# Observability Skill

ë¡œê¹…, ë©”íŠ¸ë¦­, íŠ¸ë ˆì´ì‹± ê¸°ë°˜ ê´€ì¸¡ì„±ì„ êµ¬í˜„í•©ë‹ˆë‹¤.

## Triggers

- "observability", "ëª¨ë‹ˆí„°ë§", "ë¡œê¹…", "ë©”íŠ¸ë¦­", "íŠ¸ë ˆì´ì‹±", "prometheus", "grafana"

---

## Observability Pyramid

ê´€ì¸¡ì„±ì€ ì„¸ ê°€ì§€ í•µì‹¬ ì‹ í˜¸(Three Pillars)ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. ê° ì‹ í˜¸ëŠ” ì„œë¡œ ë‹¤ë¥¸ ëª©ì ê³¼ ë¹„ìš©ì„ ê°€ì§‘ë‹ˆë‹¤.

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Traces    â”‚  â† ê°€ì¥ ìƒì„¸, ê°€ì¥ ë¹„ìŒˆ
                    â”‚  (ìƒ˜í”Œë§)    â”‚     ë””ë²„ê¹…, ì„±ëŠ¥ ë¶„ì„
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â•±               â•²
                  â•±                 â•²
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   Metrics   â”‚   â”‚    Logs     â”‚
           â”‚  (ì§‘ê³„ë¨)    â”‚   â”‚  (ìƒ˜í”Œë§)    â”‚
           â”‚ ëŒ€ì‹œë³´ë“œ/ì•Œë¦¼ â”‚   â”‚   ë””ë²„ê¹…    â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â•²                 â•±
                   â•²               â•±
                    â•²             â•±
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚      Events         â”‚  â† ê¸°ë°˜ ë°ì´í„°
               â”‚ (HTTP, DB, Cache)   â”‚     ëª¨ë“  ê´€ì¸¡ì„±ì˜ ì›ì²œ
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ì‹ í˜¸ë³„ íŠ¹ì„±

| ì‹ í˜¸ | ëª©ì  | ì €ì¥ ë¹„ìš© | ìƒ˜í”Œë§ | ì¿¼ë¦¬ ì†ë„ |
|------|------|-----------|--------|-----------|
| **Metrics** | ëŒ€ì‹œë³´ë“œ, ì•Œë¦¼, SLO | ë‚®ìŒ (ì§‘ê³„) | ë¶ˆí•„ìš” | ë¹ ë¦„ |
| **Logs** | ë””ë²„ê¹…, ê°ì‚¬ | ì¤‘ê°„ | í•„ìš” (prod) | ì¤‘ê°„ |
| **Traces** | ì„±ëŠ¥ ë¶„ì„, ì˜ì¡´ì„± ì¶”ì  | ë†’ìŒ | í•„ìˆ˜ | ëŠë¦¼ |

### ê¶Œì¥ ì „ëµ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Production í™˜ê²½ ê´€ì¸¡ì„± ì „ëµ                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚ 1. Metrics: 100% ìˆ˜ì§‘ (ì§‘ê³„ë¨, ì €ë¹„ìš©)                            â”‚
â”‚    - ëª¨ë“  ìš”ì²­ì˜ count, latency, error rate                     â”‚
â”‚    - Prometheus + Grafana                                       â”‚
â”‚                                                                 â”‚
â”‚ 2. Logs: ìƒ˜í”Œë§ ìˆ˜ì§‘                                             â”‚
â”‚    - ERROR/WARN: 100% ìˆ˜ì§‘                                      â”‚
â”‚    - INFO: 10% ìƒ˜í”Œë§ ë˜ëŠ” rate limiting                        â”‚
â”‚    - DEBUG: productionì—ì„œ ë¹„í™œì„±í™”                              â”‚
â”‚    - Loki ë˜ëŠ” Elasticsearch                                    â”‚
â”‚                                                                 â”‚
â”‚ 3. Traces: ìƒ˜í”Œë§ ìˆ˜ì§‘ (1-10%)                                   â”‚
â”‚    - ì—ëŸ¬ ë°œìƒ ì‹œ: 100% ìˆ˜ì§‘                                     â”‚
â”‚    - ì •ìƒ ìš”ì²­: 1-5% ìƒ˜í”Œë§                                      â”‚
â”‚    - ëŠë¦° ìš”ì²­ (>1s): 100% ìˆ˜ì§‘                                  â”‚
â”‚    - Jaeger ë˜ëŠ” Tempo                                          â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Input

| í•­ëª© | í•„ìˆ˜ | ì„¤ëª… |
|------|------|------|
| `projectPath` | âœ… | í”„ë¡œì íŠ¸ ê²½ë¡œ |

---

## Output

### Structured Logging

```python
# app/core/logging.py
import logging
import sys
from typing import Any

import structlog
from structlog.types import Processor

from app.core.config import settings


def setup_logging() -> None:
    """Configure structured logging."""

    # Shared processors
    shared_processors: list[Processor] = [
        structlog.contextvars.merge_contextvars,
        structlog.stdlib.add_log_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.UnicodeDecoder(),
    ]

    if settings.ENVIRONMENT == "development":
        # Development: colored console output
        processors = shared_processors + [
            structlog.dev.ConsoleRenderer(colors=True),
        ]
    else:
        # Production: JSON output
        processors = shared_processors + [
            structlog.processors.format_exc_info,
            structlog.processors.JSONRenderer(),
        ]

    structlog.configure(
        processors=processors,
        wrapper_class=structlog.stdlib.BoundLogger,
        context_class=dict,
        logger_factory=structlog.stdlib.LoggerFactory(),
        cache_logger_on_first_use=True,
    )

    # Configure stdlib logging
    logging.basicConfig(
        format="%(message)s",
        stream=sys.stdout,
        level=getattr(logging, settings.LOG_LEVEL.upper()),
    )

    # Reduce noise from third-party loggers
    logging.getLogger("uvicorn.access").setLevel(logging.WARNING)
    logging.getLogger("sqlalchemy.engine").setLevel(logging.WARNING)


def get_logger(name: str | None = None) -> structlog.stdlib.BoundLogger:
    """Get a structured logger instance."""
    return structlog.get_logger(name)
```

### Log Sampling Strategy

Production í™˜ê²½ì—ì„œ ë¡œê·¸ ë³¼ë¥¨ì„ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ìƒ˜í”Œë§ ì „ëµì…ë‹ˆë‹¤.

```python
# app/core/log_sampling.py
import random
import time
from collections import defaultdict
from functools import wraps
from threading import Lock
from typing import Callable, Any

import structlog

logger = structlog.get_logger()


class LogSampler:
    """ë¡œê·¸ ìƒ˜í”Œë§ ì „ëµ êµ¬í˜„.

    ì „ëµ:
    - ERROR/CRITICAL: í•­ìƒ 100% ê¸°ë¡
    - WARNING: 50% ìƒ˜í”Œë§
    - INFO: 10% ìƒ˜í”Œë§ + rate limiting (ì´ˆë‹¹ 100ê±´)
    - DEBUG: productionì—ì„œ ë¹„í™œì„±í™”
    """

    def __init__(
        self,
        info_sample_rate: float = 0.1,
        warn_sample_rate: float = 0.5,
        max_info_per_second: int = 100,
    ):
        self.info_sample_rate = info_sample_rate
        self.warn_sample_rate = warn_sample_rate
        self.max_info_per_second = max_info_per_second

        self._info_count = 0
        self._last_reset = time.time()
        self._lock = Lock()

        # ì¤‘ë³µ ë¡œê·¸ ì–µì œ (ê°™ì€ ë©”ì‹œì§€ ë°˜ë³µ ë°©ì§€)
        self._seen_messages: dict[str, float] = {}
        self._dedup_window = 60  # 60ì´ˆ ë‚´ ì¤‘ë³µ ì–µì œ

    def should_log(self, level: str, message: str) -> bool:
        """ë¡œê·¸ ê¸°ë¡ ì—¬ë¶€ ê²°ì •."""
        # ERROR/CRITICALì€ í•­ìƒ ê¸°ë¡
        if level in ("ERROR", "CRITICAL", "EXCEPTION"):
            return True

        # ì¤‘ë³µ ë©”ì‹œì§€ ì–µì œ
        now = time.time()
        message_key = f"{level}:{message[:100]}"
        if message_key in self._seen_messages:
            if now - self._seen_messages[message_key] < self._dedup_window:
                return False
        self._seen_messages[message_key] = now

        # ì˜¤ë˜ëœ ë©”ì‹œì§€ í‚¤ ì •ë¦¬ (ë©”ëª¨ë¦¬ ê´€ë¦¬)
        if len(self._seen_messages) > 10000:
            self._cleanup_old_messages(now)

        # WARNING: 50% ìƒ˜í”Œë§
        if level == "WARNING":
            return random.random() < self.warn_sample_rate

        # INFO: ìƒ˜í”Œë§ + rate limiting
        if level == "INFO":
            with self._lock:
                # Rate limit ë¦¬ì…‹
                if now - self._last_reset >= 1.0:
                    self._info_count = 0
                    self._last_reset = now

                # Rate limit ì´ˆê³¼ í™•ì¸
                if self._info_count >= self.max_info_per_second:
                    return False

                # ìƒ˜í”Œë§
                if random.random() >= self.info_sample_rate:
                    return False

                self._info_count += 1
                return True

        # DEBUGëŠ” productionì—ì„œ ê¸°ë³¸ ë¹„í™œì„±í™”
        return False

    def _cleanup_old_messages(self, now: float) -> None:
        """ì˜¤ë˜ëœ ë©”ì‹œì§€ í‚¤ ì •ë¦¬."""
        self._seen_messages = {
            k: v
            for k, v in self._seen_messages.items()
            if now - v < self._dedup_window
        }


# ì „ì—­ ìƒ˜í”ŒëŸ¬
_log_sampler = LogSampler()


class SampledBoundLogger:
    """ìƒ˜í”Œë§ì´ ì ìš©ëœ structlog ë˜í¼."""

    def __init__(self, base_logger: structlog.stdlib.BoundLogger):
        self._logger = base_logger

    def info(self, message: str, **kwargs: Any) -> None:
        if _log_sampler.should_log("INFO", message):
            self._logger.info(message, **kwargs)

    def warning(self, message: str, **kwargs: Any) -> None:
        if _log_sampler.should_log("WARNING", message):
            self._logger.warning(message, **kwargs)

    def error(self, message: str, **kwargs: Any) -> None:
        # ERRORëŠ” í•­ìƒ ê¸°ë¡
        self._logger.error(message, **kwargs)

    def exception(self, message: str, **kwargs: Any) -> None:
        # EXCEPTIONì€ í•­ìƒ ê¸°ë¡
        self._logger.exception(message, **kwargs)

    def debug(self, message: str, **kwargs: Any) -> None:
        if _log_sampler.should_log("DEBUG", message):
            self._logger.debug(message, **kwargs)

    # async ë²„ì „
    async def ainfo(self, message: str, **kwargs: Any) -> None:
        if _log_sampler.should_log("INFO", message):
            await self._logger.ainfo(message, **kwargs)

    async def awarning(self, message: str, **kwargs: Any) -> None:
        if _log_sampler.should_log("WARNING", message):
            await self._logger.awarning(message, **kwargs)

    async def aerror(self, message: str, **kwargs: Any) -> None:
        await self._logger.aerror(message, **kwargs)

    async def aexception(self, message: str, **kwargs: Any) -> None:
        await self._logger.aexception(message, **kwargs)


def get_sampled_logger(name: str | None = None) -> SampledBoundLogger:
    """ìƒ˜í”Œë§ì´ ì ìš©ëœ ë¡œê±° ë°˜í™˜."""
    return SampledBoundLogger(structlog.get_logger(name))
```

### ë¡œê·¸ ë ˆë²¨ë³„ ì „ëµ ìš”ì•½

| ë ˆë²¨ | ìƒ˜í”Œë§ | Rate Limit | ìš©ë„ |
|------|--------|------------|------|
| **ERROR/CRITICAL** | 100% | ì—†ìŒ | ì—ëŸ¬ ì¶”ì , ì•Œë¦¼ |
| **WARNING** | 50% | ì—†ìŒ | ì ì¬ì  ë¬¸ì œ |
| **INFO** | 10% | 100/s | ì¼ë°˜ ìš´ì˜ ë¡œê·¸ |
| **DEBUG** | 0% (prod) | - | ê°œë°œ ì‹œì—ë§Œ |

### Request Logging Middleware

```python
# app/middleware/logging.py
import time
import uuid
from typing import Callable

import structlog
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.requests import Request
from starlette.responses import Response

logger = structlog.get_logger()


class RequestLoggingMiddleware(BaseHTTPMiddleware):
    """Log all HTTP requests and responses."""

    async def dispatch(
        self,
        request: Request,
        call_next: Callable,
    ) -> Response:
        # Generate request ID
        request_id = request.headers.get("X-Request-ID") or str(uuid.uuid4())
        request.state.request_id = request_id

        # Bind request context
        structlog.contextvars.clear_contextvars()
        structlog.contextvars.bind_contextvars(
            request_id=request_id,
            method=request.method,
            path=request.url.path,
            client_ip=request.client.host if request.client else None,
        )

        # Log request
        await logger.ainfo(
            "Request started",
            query_params=dict(request.query_params),
        )

        # Process request
        start_time = time.perf_counter()
        try:
            response = await call_next(request)
            duration_ms = (time.perf_counter() - start_time) * 1000

            # Log response
            await logger.ainfo(
                "Request completed",
                status_code=response.status_code,
                duration_ms=round(duration_ms, 2),
            )

            # Add request ID to response
            response.headers["X-Request-ID"] = request_id

            return response

        except Exception as e:
            duration_ms = (time.perf_counter() - start_time) * 1000
            await logger.aexception(
                "Request failed",
                duration_ms=round(duration_ms, 2),
                error=str(e),
            )
            raise
```

### Prometheus Metrics

```python
# app/core/metrics.py
from prometheus_client import Counter, Histogram, Gauge, Info
from prometheus_client import generate_latest, CONTENT_TYPE_LATEST
from starlette.requests import Request
from starlette.responses import Response

# Application info
APP_INFO = Info("app", "Application information")

# Request metrics
REQUEST_COUNT = Counter(
    "http_requests_total",
    "Total HTTP requests",
    ["method", "endpoint", "status_code"],
)

REQUEST_LATENCY = Histogram(
    "http_request_duration_seconds",
    "HTTP request latency",
    ["method", "endpoint"],
    buckets=[0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0],
)

REQUESTS_IN_PROGRESS = Gauge(
    "http_requests_in_progress",
    "HTTP requests currently being processed",
    ["method", "endpoint"],
)

# Database metrics
DB_QUERY_COUNT = Counter(
    "db_queries_total",
    "Total database queries",
    ["operation", "table"],
)

DB_QUERY_LATENCY = Histogram(
    "db_query_duration_seconds",
    "Database query latency",
    ["operation", "table"],
    buckets=[0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0],
)

DB_CONNECTIONS_ACTIVE = Gauge(
    "db_connections_active",
    "Active database connections",
)

# Cache metrics
CACHE_HIT = Counter(
    "cache_hits_total",
    "Total cache hits",
    ["cache_type"],
)

CACHE_MISS = Counter(
    "cache_misses_total",
    "Total cache misses",
    ["cache_type"],
)

# Business metrics
USER_REGISTRATIONS = Counter(
    "user_registrations_total",
    "Total user registrations",
)

ACTIVE_USERS = Gauge(
    "active_users",
    "Currently active users",
)


def set_app_info(version: str, environment: str) -> None:
    """Set application info metrics."""
    APP_INFO.info({
        "version": version,
        "environment": environment,
    })


async def metrics_endpoint(request: Request) -> Response:
    """Prometheus metrics endpoint."""
    return Response(
        content=generate_latest(),
        media_type=CONTENT_TYPE_LATEST,
    )
```

### Metrics Middleware with Cardinality Control

```python
# app/middleware/metrics.py
import time
import re
from typing import Callable
from collections import defaultdict
from threading import Lock

from starlette.middleware.base import BaseHTTPMiddleware
from starlette.requests import Request
from starlette.responses import Response

from app.core.metrics import (
    REQUEST_COUNT,
    REQUEST_LATENCY,
    REQUESTS_IN_PROGRESS,
)


class CardinalityLimiter:
    """ë©”íŠ¸ë¦­ ì¹´ë””ë„ë¦¬í‹° í­ë°œ ë°©ì§€.

    PrometheusëŠ” ë ˆì´ë¸” ì¡°í•©ë‹¹ ë³„ë„ ì‹œê³„ì—´ì„ ìƒì„±í•©ë‹ˆë‹¤.
    - 10 endpoints Ã— 5 methods Ã— 10 status codes = 500 ì‹œê³„ì—´
    - 1000 user_idsë¥¼ ë ˆì´ë¸”ë¡œ ì¶”ê°€í•˜ë©´ = 500,000 ì‹œê³„ì—´ (ìœ„í—˜!)

    ì´ í´ë˜ìŠ¤ëŠ” ê³ ìœ  ë ˆì´ë¸” ê°’ì˜ ìˆ˜ë¥¼ ì œí•œí•©ë‹ˆë‹¤.
    """

    def __init__(self, max_unique_values: int = 100):
        self.max_unique_values = max_unique_values
        self._seen_values: dict[str, set] = defaultdict(set)
        self._lock = Lock()

    def get_safe_label(self, label_name: str, value: str, fallback: str = "other") -> str:
        """ì¹´ë””ë„ë¦¬í‹° ì œí•œì„ ì ìš©í•œ ë ˆì´ë¸” ê°’ ë°˜í™˜."""
        with self._lock:
            seen = self._seen_values[label_name]

            if value in seen:
                return value

            if len(seen) < self.max_unique_values:
                seen.add(value)
                return value

            # í•œë„ ì´ˆê³¼ ì‹œ fallback ë°˜í™˜
            return fallback


# ì „ì—­ ì¹´ë””ë„ë¦¬í‹° ì œí•œê¸°
_cardinality_limiter = CardinalityLimiter(max_unique_values=100)


class MetricsMiddleware(BaseHTTPMiddleware):
    """Collect Prometheus metrics for HTTP requests."""

    # ì•Œë ¤ì§„ API ì—”ë“œí¬ì¸íŠ¸ (í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ë°©ì‹ ê¶Œì¥)
    KNOWN_ENDPOINTS = {
        "/api/v1/users",
        "/api/v1/users/{id}",
        "/api/v1/auth/login",
        "/api/v1/auth/logout",
        "/api/v1/items",
        "/api/v1/items/{id}",
        "/health",
        "/health/ready",
        "/health/live",
        "/metrics",
    }

    async def dispatch(
        self,
        request: Request,
        call_next: Callable,
    ) -> Response:
        method = request.method
        # Normalize path to avoid high cardinality
        path = self._normalize_path(request.url.path)

        # ì¹´ë””ë„ë¦¬í‹° ì•ˆì „ ë ˆì´ë¸”
        safe_path = _cardinality_limiter.get_safe_label("endpoint", path, "/unknown")

        # Track in-progress requests
        REQUESTS_IN_PROGRESS.labels(method=method, endpoint=safe_path).inc()

        start_time = time.perf_counter()
        try:
            response = await call_next(request)
            status_code = response.status_code
        except Exception:
            status_code = 500
            raise
        finally:
            # Record request duration
            duration = time.perf_counter() - start_time
            REQUEST_LATENCY.labels(method=method, endpoint=safe_path).observe(duration)

            # ìƒíƒœ ì½”ë“œë„ ê·¸ë£¹í™” (2xx, 4xx, 5xx)
            status_group = f"{status_code // 100}xx"

            # Record request count
            REQUEST_COUNT.labels(
                method=method,
                endpoint=safe_path,
                status_code=status_group,  # ê°œë³„ ì½”ë“œ ëŒ€ì‹  ê·¸ë£¹ ì‚¬ìš©
            ).inc()

            # Decrease in-progress counter
            REQUESTS_IN_PROGRESS.labels(method=method, endpoint=safe_path).dec()

        return response

    def _normalize_path(self, path: str) -> str:
        """Normalize path to reduce cardinality.

        ì¹´ë””ë„ë¦¬í‹° ê´€ë¦¬ í•µì‹¬:
        - /users/123 â†’ /users/{id}
        - /items/abc-def-123 â†’ /items/{uuid}
        - ì•Œ ìˆ˜ ì—†ëŠ” ê²½ë¡œ â†’ /unknown
        """
        # Replace numeric IDs
        path = re.sub(r'/\d+', '/{id}', path)
        # Replace UUIDs
        path = re.sub(
            r'/[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}',
            '/{uuid}',
            path,
            flags=re.IGNORECASE,
        )
        # Replace slugs (alphanumeric with hyphens, likely dynamic)
        path = re.sub(r'/[a-z0-9]+-[a-z0-9-]+', '/{slug}', path, flags=re.IGNORECASE)

        # í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ì— ì—†ìœ¼ë©´ unknown ì²˜ë¦¬
        if path not in self.KNOWN_ENDPOINTS:
            # ìµœì†Œí•œ ì²« ë²ˆì§¸ ì„¸ê·¸ë¨¼íŠ¸ëŠ” ìœ ì§€
            segments = path.split('/')
            if len(segments) > 2:
                path = '/'.join(segments[:3]) + '/...'

        return path
```

### ì¹´ë””ë„ë¦¬í‹° ê´€ë¦¬ Best Practices

| ìœ„í—˜ ìˆ˜ì¤€ | ë ˆì´ë¸” ì˜ˆì‹œ | ì¡°ì¹˜ |
|-----------|------------|------|
| ğŸ”´ **ë†’ìŒ** | `user_id`, `session_id`, `request_id` | ì ˆëŒ€ ë ˆì´ë¸”ë¡œ ì‚¬ìš© ê¸ˆì§€ |
| ğŸŸ  **ì¤‘ê°„** | `endpoint` (ë™ì  ê²½ë¡œ í¬í•¨) | ì •ê·œí™” í•„ìˆ˜ (`/{id}`) |
| ğŸŸ¡ **ë‚®ìŒ** | `status_code` (ê°œë³„ ì½”ë“œ) | ê·¸ë£¹í™” ê¶Œì¥ (`2xx`, `4xx`) |
| ğŸŸ¢ **ì•ˆì „** | `method`, `service`, `environment` | ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥ |

```python
# âŒ ë‚˜ìœ ì˜ˆ: ê³ ì¹´ë””ë„ë¦¬í‹° ë ˆì´ë¸”
REQUEST_COUNT = Counter(
    "http_requests_total",
    "Total requests",
    ["method", "endpoint", "status_code", "user_id"],  # user_id ìœ„í—˜!
)

# âœ… ì¢‹ì€ ì˜ˆ: ì €ì¹´ë””ë„ë¦¬í‹° ë ˆì´ë¸”
REQUEST_COUNT = Counter(
    "http_requests_total",
    "Total requests",
    ["method", "endpoint", "status_group"],  # status_group: 2xx, 4xx, 5xx
)

# ì‚¬ìš©ìë³„ ë©”íŠ¸ë¦­ì´ í•„ìš”í•˜ë©´ ë³„ë„ Counter ì‚¬ìš©
USER_ACTIONS = Counter(
    "user_actions_total",
    "User action counts",
    ["action"],  # login, logout, purchase ë“± ì œí•œëœ ê°’
)
```

### OpenTelemetry Tracing

```python
# app/core/tracing.py
from opentelemetry import trace
from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor
from opentelemetry.instrumentation.httpx import HTTPXClientInstrumentor
from opentelemetry.instrumentation.sqlalchemy import SQLAlchemyInstrumentor
from opentelemetry.instrumentation.redis import RedisInstrumentor
from opentelemetry.sdk.resources import Resource
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.semconv.resource import ResourceAttributes

from app.core.config import settings


def setup_tracing() -> None:
    """Configure OpenTelemetry tracing."""
    if not settings.OTEL_ENABLED:
        return

    # Create resource
    resource = Resource.create({
        ResourceAttributes.SERVICE_NAME: settings.PROJECT_NAME,
        ResourceAttributes.SERVICE_VERSION: settings.VERSION,
        ResourceAttributes.DEPLOYMENT_ENVIRONMENT: settings.ENVIRONMENT,
    })

    # Create tracer provider
    provider = TracerProvider(resource=resource)

    # Add OTLP exporter
    otlp_exporter = OTLPSpanExporter(
        endpoint=settings.OTEL_EXPORTER_OTLP_ENDPOINT,
    )
    provider.add_span_processor(BatchSpanProcessor(otlp_exporter))

    # Set global tracer provider
    trace.set_tracer_provider(provider)


def instrument_app(app) -> None:
    """Instrument FastAPI application."""
    if not settings.OTEL_ENABLED:
        return

    # Instrument FastAPI
    FastAPIInstrumentor.instrument_app(app)

    # Instrument HTTP client
    HTTPXClientInstrumentor().instrument()

    # Instrument Redis
    RedisInstrumentor().instrument()


def instrument_database(engine) -> None:
    """Instrument SQLAlchemy (sync engine only).

    ì£¼ì˜: SQLAlchemyInstrumentorëŠ” sync_engineë§Œ ì§€ì›í•©ë‹ˆë‹¤.
    AsyncSession ì‚¬ìš© ì‹œ ë³„ë„ ì²˜ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.
    """
    if not settings.OTEL_ENABLED:
        return

    SQLAlchemyInstrumentor().instrument(engine=engine.sync_engine)


def get_tracer(name: str = __name__) -> trace.Tracer:
    """Get a tracer instance."""
    return trace.get_tracer(name)
```

### OpenTelemetry Async Database Instrumentation

SQLAlchemy 2.0 async ì—”ì§„ì€ ê¸°ë³¸ Instrumentorì—ì„œ ì™„ì „íˆ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
ìˆ˜ë™ìœ¼ë¡œ async ì¿¼ë¦¬ë¥¼ ì¶”ì í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

```python
# app/core/tracing_async.py
from contextlib import asynccontextmanager
from typing import AsyncIterator, Any

from opentelemetry import trace
from opentelemetry.trace import Status, StatusCode
from sqlalchemy.ext.asyncio import AsyncSession

tracer = trace.get_tracer(__name__)


@asynccontextmanager
async def traced_db_session(
    session: AsyncSession,
    operation: str = "db.query",
) -> AsyncIterator[AsyncSession]:
    """Async DB ì„¸ì…˜ì— íŠ¸ë ˆì´ì‹± ì¶”ê°€.

    ì‚¬ìš© ì˜ˆ:
        async with traced_db_session(session, "users.list") as sess:
            result = await sess.execute(select(User))
    """
    with tracer.start_as_current_span(
        operation,
        attributes={
            "db.system": "postgresql",
            "db.operation": operation,
        },
    ) as span:
        try:
            yield session
            span.set_status(Status(StatusCode.OK))
        except Exception as e:
            span.set_status(Status(StatusCode.ERROR, str(e)))
            span.record_exception(e)
            raise


class TracedAsyncSession:
    """íŠ¸ë ˆì´ì‹±ì´ ì ìš©ëœ AsyncSession ë˜í¼.

    Repositoryì—ì„œ ì‚¬ìš©:
        class UserRepository:
            def __init__(self, session: AsyncSession):
                self._session = TracedAsyncSession(session)

            async def get_by_id(self, user_id: int) -> User | None:
                return await self._session.execute(
                    select(User).where(User.id == user_id),
                    operation="users.get_by_id",
                )
    """

    def __init__(self, session: AsyncSession):
        self._session = session

    async def execute(
        self,
        statement: Any,
        operation: str = "db.execute",
        **kwargs: Any,
    ):
        """íŠ¸ë ˆì´ì‹±ì´ ì ìš©ëœ execute."""
        with tracer.start_as_current_span(
            operation,
            attributes={
                "db.system": "postgresql",
                "db.statement": str(statement)[:500],  # ì¿¼ë¦¬ ì¼ë¶€ë§Œ ê¸°ë¡
            },
        ) as span:
            try:
                result = await self._session.execute(statement, **kwargs)
                span.set_attribute("db.rows_affected", result.rowcount or 0)
                span.set_status(Status(StatusCode.OK))
                return result
            except Exception as e:
                span.set_status(Status(StatusCode.ERROR, str(e)))
                span.record_exception(e)
                raise

    async def commit(self) -> None:
        """íŠ¸ë ˆì´ì‹±ì´ ì ìš©ëœ commit."""
        with tracer.start_as_current_span("db.commit") as span:
            try:
                await self._session.commit()
                span.set_status(Status(StatusCode.OK))
            except Exception as e:
                span.set_status(Status(StatusCode.ERROR, str(e)))
                span.record_exception(e)
                raise

    async def rollback(self) -> None:
        """íŠ¸ë ˆì´ì‹±ì´ ì ìš©ëœ rollback."""
        with tracer.start_as_current_span("db.rollback") as span:
            await self._session.rollback()
            span.set_status(Status(StatusCode.OK))


# Repositoryì—ì„œ ì‚¬ìš©í•˜ëŠ” ë°ì½”ë ˆì´í„°
def trace_db_operation(operation: str):
    """DB ì‘ì—…ì— íŠ¸ë ˆì´ì‹± ì¶”ê°€í•˜ëŠ” ë°ì½”ë ˆì´í„°.

    ì‚¬ìš© ì˜ˆ:
        @trace_db_operation("users.create")
        async def create_user(session: AsyncSession, user: UserCreate) -> User:
            ...
    """
    def decorator(func):
        async def wrapper(*args, **kwargs):
            with tracer.start_as_current_span(
                operation,
                attributes={"db.system": "postgresql"},
            ) as span:
                try:
                    result = await func(*args, **kwargs)
                    span.set_status(Status(StatusCode.OK))
                    return result
                except Exception as e:
                    span.set_status(Status(StatusCode.ERROR, str(e)))
                    span.record_exception(e)
                    raise
        return wrapper
    return decorator
```

### Health Check Endpoints

```python
# app/api/health.py
from datetime import datetime, timezone

from fastapi import APIRouter, Depends
from pydantic import BaseModel
from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncSession

from app.api.v1.dependencies import get_async_session
from app.core.config import settings

router = APIRouter(tags=["health"])


class HealthStatus(BaseModel):
    """Health check response."""

    status: str
    version: str
    environment: str
    timestamp: datetime


class ReadinessStatus(BaseModel):
    """Readiness check response."""

    status: str
    checks: dict[str, bool]


@router.get("/health", response_model=HealthStatus)
async def health_check():
    """Liveness probe - basic health check."""
    return HealthStatus(
        status="healthy",
        version=settings.VERSION,
        environment=settings.ENVIRONMENT,
        timestamp=datetime.now(timezone.utc),
    )


@router.get("/health/ready", response_model=ReadinessStatus)
async def readiness_check(
    session: AsyncSession = Depends(get_async_session),
):
    """Readiness probe - check all dependencies."""
    checks = {}

    # Check database
    try:
        await session.execute(text("SELECT 1"))
        checks["database"] = True
    except Exception:
        checks["database"] = False

    # Check Redis
    try:
        from app.infrastructure.cache.redis import redis_client
        await redis_client.ping()
        checks["redis"] = True
    except Exception:
        checks["redis"] = False

    # Overall status
    all_healthy = all(checks.values())

    return ReadinessStatus(
        status="ready" if all_healthy else "not_ready",
        checks=checks,
    )


@router.get("/health/live")
async def liveness_check():
    """Simple liveness check for Kubernetes."""
    return {"status": "alive"}
```

### Sentry Integration

```python
# app/core/sentry.py
import sentry_sdk
from sentry_sdk.integrations.asyncio import AsyncioIntegration
from sentry_sdk.integrations.fastapi import FastApiIntegration
from sentry_sdk.integrations.sqlalchemy import SqlalchemyIntegration
from sentry_sdk.integrations.redis import RedisIntegration
from sentry_sdk.integrations.celery import CeleryIntegration

from app.core.config import settings


def setup_sentry() -> None:
    """Configure Sentry error tracking."""
    if not settings.SENTRY_DSN:
        return

    sentry_sdk.init(
        dsn=settings.SENTRY_DSN,
        environment=settings.ENVIRONMENT,
        release=settings.VERSION,
        traces_sample_rate=0.1 if settings.ENVIRONMENT == "production" else 1.0,
        profiles_sample_rate=0.1,
        integrations=[
            FastApiIntegration(transaction_style="endpoint"),
            AsyncioIntegration(),
            SqlalchemyIntegration(),
            RedisIntegration(),
            CeleryIntegration(),
        ],
        # Don't send PII
        send_default_pii=False,
        # Filter sensitive data
        before_send=filter_sensitive_data,
    )


def filter_sensitive_data(event, hint):
    """Filter sensitive data from Sentry events."""
    # Remove sensitive headers
    if "request" in event and "headers" in event["request"]:
        headers = event["request"]["headers"]
        sensitive_headers = ["authorization", "cookie", "x-api-key"]
        for header in sensitive_headers:
            if header in headers:
                headers[header] = "[FILTERED]"

    # Remove sensitive query params
    if "request" in event and "query_string" in event["request"]:
        query = event["request"]["query_string"]
        if "password" in query or "token" in query:
            event["request"]["query_string"] = "[FILTERED]"

    return event


def capture_exception(exception: Exception, **extra) -> None:
    """Capture exception with additional context."""
    with sentry_sdk.push_scope() as scope:
        for key, value in extra.items():
            scope.set_extra(key, value)
        sentry_sdk.capture_exception(exception)


def set_user_context(user_id: int, email: str) -> None:
    """Set user context for Sentry."""
    sentry_sdk.set_user({
        "id": str(user_id),
        "email": email,
    })
```

### Grafana Dashboard - Complete Configuration

```json
{
  "dashboard": {
    "uid": "fastapi-app",
    "title": "FastAPI Application Dashboard",
    "tags": ["fastapi", "api", "monitoring"],
    "timezone": "browser",
    "refresh": "30s",
    "schemaVersion": 38,
    "panels": [
      {
        "id": 1,
        "title": "Request Rate (RPS)",
        "type": "timeseries",
        "gridPos": {"x": 0, "y": 0, "w": 12, "h": 8},
        "targets": [
          {
            "expr": "sum(rate(http_requests_total[5m])) by (method)",
            "legendFormat": "{{method}}"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "reqps",
            "custom": {"lineWidth": 2, "fillOpacity": 10}
          }
        }
      },
      {
        "id": 2,
        "title": "Request Latency Percentiles",
        "type": "timeseries",
        "gridPos": {"x": 12, "y": 0, "w": 12, "h": 8},
        "targets": [
          {
            "expr": "histogram_quantile(0.50, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "p50"
          },
          {
            "expr": "histogram_quantile(0.90, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "p90"
          },
          {
            "expr": "histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "p99"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "s",
            "custom": {"lineWidth": 2}
          }
        }
      },
      {
        "id": 3,
        "title": "Error Rate (%)",
        "type": "timeseries",
        "gridPos": {"x": 0, "y": 8, "w": 8, "h": 6},
        "targets": [
          {
            "expr": "sum(rate(http_requests_total{status_code=~\"5..\"}[5m])) / sum(rate(http_requests_total[5m])) * 100",
            "legendFormat": "5xx Error Rate"
          },
          {
            "expr": "sum(rate(http_requests_total{status_code=~\"4..\"}[5m])) / sum(rate(http_requests_total[5m])) * 100",
            "legendFormat": "4xx Error Rate"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percent",
            "thresholds": {
              "mode": "absolute",
              "steps": [
                {"color": "green", "value": null},
                {"color": "yellow", "value": 1},
                {"color": "red", "value": 5}
              ]
            }
          }
        }
      },
      {
        "id": 4,
        "title": "Active DB Connections",
        "type": "gauge",
        "gridPos": {"x": 8, "y": 8, "w": 4, "h": 6},
        "targets": [
          {"expr": "db_connections_active"}
        ],
        "fieldConfig": {
          "defaults": {
            "min": 0,
            "max": 100,
            "thresholds": {
              "steps": [
                {"color": "green", "value": null},
                {"color": "yellow", "value": 70},
                {"color": "red", "value": 90}
              ]
            }
          }
        }
      },
      {
        "id": 5,
        "title": "Cache Hit Rate (%)",
        "type": "gauge",
        "gridPos": {"x": 12, "y": 8, "w": 4, "h": 6},
        "targets": [
          {
            "expr": "sum(rate(cache_hits_total[5m])) / (sum(rate(cache_hits_total[5m])) + sum(rate(cache_misses_total[5m]))) * 100"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percent",
            "min": 0,
            "max": 100,
            "thresholds": {
              "steps": [
                {"color": "red", "value": null},
                {"color": "yellow", "value": 70},
                {"color": "green", "value": 90}
              ]
            }
          }
        }
      },
      {
        "id": 6,
        "title": "Requests In Progress",
        "type": "stat",
        "gridPos": {"x": 16, "y": 8, "w": 4, "h": 6},
        "targets": [
          {"expr": "sum(http_requests_in_progress)"}
        ],
        "fieldConfig": {
          "defaults": {"unit": "none"}
        }
      },
      {
        "id": 7,
        "title": "Active Users",
        "type": "stat",
        "gridPos": {"x": 20, "y": 8, "w": 4, "h": 6},
        "targets": [
          {"expr": "active_users"}
        ],
        "fieldConfig": {
          "defaults": {"unit": "none", "color": {"mode": "thresholds"}}
        }
      },
      {
        "id": 8,
        "title": "DB Query Latency by Operation",
        "type": "timeseries",
        "gridPos": {"x": 0, "y": 14, "w": 12, "h": 6},
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(db_query_duration_seconds_bucket[5m])) by (operation)",
            "legendFormat": "{{operation}} p95"
          }
        ],
        "fieldConfig": {
          "defaults": {"unit": "s"}
        }
      },
      {
        "id": 9,
        "title": "Top Endpoints by Latency",
        "type": "table",
        "gridPos": {"x": 12, "y": 14, "w": 12, "h": 6},
        "targets": [
          {
            "expr": "topk(10, histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m])) by (endpoint))",
            "format": "table",
            "instant": true
          }
        ],
        "transformations": [
          {"id": "organize", "options": {"renameByName": {"Value": "p99 Latency (s)"}}}
        ]
      },
      {
        "id": 10,
        "title": "User Registrations",
        "type": "timeseries",
        "gridPos": {"x": 0, "y": 20, "w": 12, "h": 6},
        "targets": [
          {
            "expr": "increase(user_registrations_total[1h])",
            "legendFormat": "Registrations/hour"
          }
        ]
      },
      {
        "id": 11,
        "title": "Status Code Distribution",
        "type": "piechart",
        "gridPos": {"x": 12, "y": 20, "w": 6, "h": 6},
        "targets": [
          {
            "expr": "sum by (status_code) (increase(http_requests_total[1h]))",
            "legendFormat": "{{status_code}}"
          }
        ]
      },
      {
        "id": 12,
        "title": "Memory Usage",
        "type": "timeseries",
        "gridPos": {"x": 18, "y": 20, "w": 6, "h": 6},
        "targets": [
          {
            "expr": "process_resident_memory_bytes / 1024 / 1024",
            "legendFormat": "RSS (MB)"
          }
        ],
        "fieldConfig": {
          "defaults": {"unit": "decmbytes"}
        }
      }
    ],
    "templating": {
      "list": [
        {
          "name": "environment",
          "type": "custom",
          "options": [
            {"text": "production", "value": "production"},
            {"text": "staging", "value": "staging"}
          ],
          "current": {"text": "production", "value": "production"}
        }
      ]
    },
    "annotations": {
      "list": [
        {
          "name": "Deployments",
          "datasource": "Prometheus",
          "expr": "changes(app_info[5m]) > 0",
          "enable": true,
          "iconColor": "blue"
        }
      ]
    }
  }
}
```

### Key Grafana Queries Reference

| Metric | PromQL Query | Purpose |
|--------|--------------|---------|
| **RPS** | `sum(rate(http_requests_total[5m]))` | Requests per second |
| **p99 Latency** | `histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))` | 99th percentile latency |
| **Error Rate** | `sum(rate(http_requests_total{status_code=~"5.."}[5m])) / sum(rate(http_requests_total[5m])) * 100` | 5xx error percentage |
| **Apdex** | `(sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m])) + sum(rate(http_request_duration_seconds_bucket{le="2.0"}[5m])) / 2) / sum(rate(http_request_duration_seconds_count[5m]))` | User satisfaction score |
| **Cache Hit Rate** | `sum(rate(cache_hits_total[5m])) / (sum(rate(cache_hits_total[5m])) + sum(rate(cache_misses_total[5m]))) * 100` | Cache effectiveness |
| **Saturation** | `sum(http_requests_in_progress)` | Current load |

### Alert Rules

```yaml
# prometheus/alerts.yml
groups:
  - name: fastapi-alerts
    rules:
      - alert: HighErrorRate
        expr: sum(rate(http_requests_total{status_code=~"5.."}[5m])) / sum(rate(http_requests_total[5m])) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected (>5%)"
          description: "Error rate is {{ $value | printf \"%.2f\" }}%"

      - alert: HighLatency
        expr: histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m])) > 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High p99 latency (>2s)"

      - alert: DatabaseConnectionsHigh
        expr: db_connections_active > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Database connections above 80%"
```

### Environment Settings

```python
# Add to app/core/config.py

class Settings(BaseSettings):
    # ... existing settings ...

    # Logging
    LOG_LEVEL: str = "INFO"

    # OpenTelemetry
    OTEL_ENABLED: bool = False
    OTEL_EXPORTER_OTLP_ENDPOINT: str = "http://localhost:4317"

    # Sentry
    SENTRY_DSN: str | None = None
```

### Main App Integration

```python
# app/main.py
from contextlib import asynccontextmanager
from typing import AsyncIterator

from fastapi import FastAPI

from app.core.config import settings
from app.core.logging import setup_logging
from app.core.metrics import set_app_info, metrics_endpoint
from app.core.tracing import setup_tracing, instrument_app
from app.core.sentry import setup_sentry
from app.middleware.logging import RequestLoggingMiddleware
from app.middleware.metrics import MetricsMiddleware


@asynccontextmanager
async def lifespan(app: FastAPI) -> AsyncIterator[None]:
    """Application lifespan handler."""
    # Startup
    setup_logging()
    setup_tracing()
    setup_sentry()
    set_app_info(settings.VERSION, settings.ENVIRONMENT)

    yield

    # Shutdown
    pass


def create_app() -> FastAPI:
    app = FastAPI(
        title=settings.PROJECT_NAME,
        version=settings.VERSION,
        lifespan=lifespan,
    )

    # Add middleware
    app.add_middleware(RequestLoggingMiddleware)
    app.add_middleware(MetricsMiddleware)

    # Instrument for tracing
    instrument_app(app)

    # Add metrics endpoint
    app.add_route("/metrics", metrics_endpoint)

    # Include routers
    from app.api.health import router as health_router
    app.include_router(health_router)

    return app
```

---

## Grafana Datasource Provisioning

Grafanaë¥¼ ì½”ë“œë¡œ ì„¤ì •í•˜ì—¬ ì¬í˜„ ê°€ëŠ¥í•œ ëŒ€ì‹œë³´ë“œ í™˜ê²½ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.

### Datasource í”„ë¡œë¹„ì €ë‹

```yaml
# grafana/provisioning/datasources/datasources.yaml
apiVersion: 1

datasources:
  # Prometheus - ë©”íŠ¸ë¦­
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
    editable: false
    jsonData:
      httpMethod: POST
      timeInterval: "15s"
      exemplarTraceIdDestinations:
        - name: traceID
          datasourceUid: tempo

  # Loki - ë¡œê·¸
  - name: Loki
    type: loki
    access: proxy
    url: http://loki:3100
    editable: false
    jsonData:
      derivedFields:
        - datasourceUid: tempo
          matcherRegex: '"trace_id":"([^"]+)"'
          name: TraceID
          url: '$${__value.raw}'

  # Tempo - íŠ¸ë ˆì´ìŠ¤
  - name: Tempo
    type: tempo
    access: proxy
    url: http://tempo:3200
    uid: tempo
    editable: false
    jsonData:
      tracesToLogs:
        datasourceUid: loki
        filterByTraceID: true
        filterBySpanID: true
      tracesToMetrics:
        datasourceUid: prometheus
        queries:
          - name: Request rate
            query: 'sum(rate(http_requests_total{$$__tags}[5m]))'

  # AlertManager
  - name: Alertmanager
    type: alertmanager
    access: proxy
    url: http://alertmanager:9093
    editable: false
    jsonData:
      implementation: prometheus
```

### Dashboard í”„ë¡œë¹„ì €ë‹

```yaml
# grafana/provisioning/dashboards/dashboards.yaml
apiVersion: 1

providers:
  - name: 'FastAPI Dashboards'
    orgId: 1
    folder: 'FastAPI'
    folderUid: 'fastapi'
    type: file
    disableDeletion: true
    editable: false
    options:
      path: /var/lib/grafana/dashboards/fastapi
```

### Docker Compose Grafana ì„¤ì •

```yaml
# docker-compose.monitoring.yml
services:
  grafana:
    image: grafana/grafana:11.0.0
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
      - ./grafana/dashboards:/var/lib/grafana/dashboards
    depends_on:
      - prometheus
      - loki
      - tempo
```

---

## AlertManager Configuration

Prometheus ì•Œë¦¼ì„ ë¼ìš°íŒ…í•˜ê³  ê·¸ë£¹í™”í•˜ì—¬ ì „ë‹¬í•©ë‹ˆë‹¤.

### AlertManager ì„¤ì •

```yaml
# alertmanager/alertmanager.yml
global:
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_from: 'alertmanager@example.com'
  smtp_auth_username: 'alertmanager@example.com'
  smtp_auth_password: '${SMTP_PASSWORD}'

  slack_api_url: '${SLACK_WEBHOOK_URL}'

# ë¼ìš°íŒ… ê·œì¹™
route:
  group_by: ['alertname', 'severity']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  receiver: 'default-receiver'

  routes:
    # Critical ì•Œë¦¼ â†’ PagerDuty + Slack
    - match:
        severity: critical
      receiver: 'critical-receiver'
      group_wait: 10s
      repeat_interval: 1h

    # Warning ì•Œë¦¼ â†’ Slackë§Œ
    - match:
        severity: warning
      receiver: 'warning-receiver'
      repeat_interval: 4h

    # DB ê´€ë ¨ ì•Œë¦¼ â†’ DBAíŒ€
    - match_re:
        alertname: 'Database.*'
      receiver: 'dba-team'

# ì–µì œ ê·œì¹™ (ì¤‘ë³µ ì•Œë¦¼ ë°©ì§€)
inhibit_rules:
  # Critical ë°œìƒ ì‹œ Warning ì–µì œ
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'instance']

# ìˆ˜ì‹ ì ì •ì˜
receivers:
  - name: 'default-receiver'
    slack_configs:
      - channel: '#alerts-default'
        send_resolved: true
        title: '{{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

  - name: 'critical-receiver'
    slack_configs:
      - channel: '#alerts-critical'
        send_resolved: true
        color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
        title: 'ğŸš¨ CRITICAL: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Summary:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Runbook:* {{ .Annotations.runbook_url }}
          {{ end }}
    pagerduty_configs:
      - service_key: '${PAGERDUTY_SERVICE_KEY}'
        severity: critical
        description: '{{ .GroupLabels.alertname }}'

  - name: 'warning-receiver'
    slack_configs:
      - channel: '#alerts-warning'
        send_resolved: true
        color: 'warning'
        title: 'âš ï¸ WARNING: {{ .GroupLabels.alertname }}'

  - name: 'dba-team'
    email_configs:
      - to: 'dba-team@example.com'
        send_resolved: true
    slack_configs:
      - channel: '#dba-alerts'
```

### Prometheus Alert Rules í™•ì¥

```yaml
# prometheus/rules/fastapi-alerts.yml
groups:
  - name: fastapi.rules
    rules:
      # SLO: 99.9% ê°€ìš©ì„±
      - alert: HighErrorRateCritical
        expr: |
          (
            sum(rate(http_requests_total{status_code=~"5.."}[5m]))
            / sum(rate(http_requests_total[5m]))
          ) > 0.001
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "ì—ëŸ¬ìœ¨ì´ SLO(99.9%)ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤"
          description: "í˜„ì¬ ì—ëŸ¬ìœ¨: {{ $value | humanizePercentage }}"
          runbook_url: "https://runbooks.example.com/high-error-rate"

      # SLO: P99 latency < 500ms
      - alert: HighLatencyCritical
        expr: |
          histogram_quantile(0.99,
            sum(rate(http_request_duration_seconds_bucket[5m])) by (le)
          ) > 0.5
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "P99 ë ˆì´í„´ì‹œê°€ 500msë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤"
          description: "í˜„ì¬ P99: {{ $value | humanizeDuration }}"

      # DB ì—°ê²° ê³ ê°ˆ ì˜ˆë°©
      - alert: DatabaseConnectionsHigh
        expr: db_connections_active > 0.8 * db_connections_max
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "DB ì—°ê²°ì´ 80%ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤"
          description: "í™œì„± ì—°ê²°: {{ $value }}"

      # Pod ì¬ì‹œì‘ ê°ì§€
      - alert: PodRestartingFrequently
        expr: |
          increase(kube_pod_container_status_restarts_total{
            container="api"
          }[1h]) > 3
        labels:
          severity: warning
        annotations:
          summary: "Podê°€ 1ì‹œê°„ ë‚´ 3íšŒ ì´ìƒ ì¬ì‹œì‘ë¨"
          description: "Pod {{ $labels.pod }}ê°€ ë¹ˆë²ˆí•˜ê²Œ ì¬ì‹œì‘ë˜ê³  ìˆìŠµë‹ˆë‹¤"
```

---

## Loki Log Aggregation

Grafana Lokië¥¼ ì‚¬ìš©í•œ ë¡œê·¸ ì§‘ê³„ ë° ì¿¼ë¦¬ì…ë‹ˆë‹¤.

### Loki ì„¤ì •

```yaml
# loki/loki-config.yaml
auth_enabled: false

server:
  http_listen_port: 3100

common:
  path_prefix: /loki
  storage:
    filesystem:
      chunks_directory: /loki/chunks
      rules_directory: /loki/rules
  replication_factor: 1
  ring:
    kvstore:
      store: inmemory

schema_config:
  configs:
    - from: 2024-01-01
      store: tsdb
      object_store: filesystem
      schema: v13
      index:
        prefix: index_
        period: 24h

limits_config:
  # ë¡œê·¸ ë³¼ë¥¨ ì œí•œ
  ingestion_rate_mb: 10
  ingestion_burst_size_mb: 20
  max_streams_per_user: 10000
  max_entries_limit_per_query: 5000

  # ë³´ì¡´ ê¸°ê°„
  retention_period: 168h  # 7ì¼

# ì••ì¶• ì„¤ì •
compactor:
  working_directory: /loki/compactor
  shared_store: filesystem
  compaction_interval: 10m
  retention_enabled: true
  retention_delete_delay: 2h
```

### Promtail (ë¡œê·¸ ìˆ˜ì§‘ê¸°) ì„¤ì •

```yaml
# promtail/promtail-config.yaml
server:
  http_listen_port: 9080

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  # Kubernetes Pod ë¡œê·¸
  - job_name: kubernetes-pods
    kubernetes_sd_configs:
      - role: pod
    pipeline_stages:
      # JSON ë¡œê·¸ íŒŒì‹±
      - json:
          expressions:
            level: level
            message: event
            request_id: request_id
            trace_id: trace_id
      # ë ˆì´ë¸” ì¶”ì¶œ
      - labels:
          level:
          request_id:
          trace_id:
      # íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì‹±
      - timestamp:
          source: timestamp
          format: RFC3339Nano
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_app]
        target_label: app
      - source_labels: [__meta_kubernetes_namespace]
        target_label: namespace
      - source_labels: [__meta_kubernetes_pod_name]
        target_label: pod

  # FastAPI ì•± ë¡œê·¸ (Docker í™˜ê²½)
  - job_name: fastapi-app
    static_configs:
      - targets:
          - localhost
        labels:
          job: fastapi-app
          __path__: /var/log/fastapi/*.log
    pipeline_stages:
      - json:
          expressions:
            level: level
            message: event
            request_id: request_id
            duration_ms: duration_ms
      - labels:
          level:
      - metrics:
          log_lines_total:
            type: Counter
            description: "Total log lines"
            source: level
            config:
              action: inc
```

### LogQL ì¿¼ë¦¬ ì˜ˆì‹œ

```promql
# ìµœê·¼ ì—ëŸ¬ ë¡œê·¸
{app="fastapi-app"} |= "error" | json

# íŠ¹ì • request_idë¡œ ì¶”ì 
{app="fastapi-app"} | json | request_id="abc-123"

# ëŠë¦° ìš”ì²­ (>1ì´ˆ)
{app="fastapi-app"} | json | duration_ms > 1000

# ì—ëŸ¬ìœ¨ ê³„ì‚° (ë¶„ë‹¹)
sum(rate({app="fastapi-app"} | json | level="ERROR" [1m]))

# ìƒìœ„ 10ê°œ ì—ëŸ¬ ë©”ì‹œì§€
topk(10, sum by (message) (count_over_time({app="fastapi-app"} | json | level="ERROR" [1h])))

# Trace IDë¡œ ë¡œê·¸-íŠ¸ë ˆì´ìŠ¤ ì—°ê²°
{app="fastapi-app"} | json | trace_id="abc123"
```

### Python ë¡œê·¸ â†’ Loki ì—°ë™

```python
# app/core/logging.py ì— ì¶”ê°€
import logging_loki

def setup_loki_handler() -> None:
    """Lokië¡œ ë¡œê·¸ ì „ì†¡ ì„¤ì •."""
    if not settings.LOKI_URL:
        return

    handler = logging_loki.LokiHandler(
        url=f"{settings.LOKI_URL}/loki/api/v1/push",
        tags={"app": settings.PROJECT_NAME, "environment": settings.ENVIRONMENT},
        version="1",
    )

    # structlogì™€ í•¨ê»˜ ì‚¬ìš©
    logging.getLogger().addHandler(handler)
```

---

## Observability Stack

| Component | Tool | Purpose |
|-----------|------|---------|
| Logging | structlog + Loki | Structured JSON logs + ì§‘ê³„ |
| Metrics | Prometheus | Time-series metrics |
| Tracing | OpenTelemetry + Tempo | Distributed tracing |
| Errors | Sentry | Error tracking |
| Visualization | Grafana | Unified dashboards |
| Alerting | AlertManager | Alert routing & grouping |

### í†µí•© ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Grafana                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Dashboards  â”‚  â”‚   Alerts    â”‚  â”‚  Explore    â”‚  â”‚  Unified   â”‚ â”‚
â”‚  â”‚             â”‚  â”‚             â”‚  â”‚  (Logs/     â”‚  â”‚  Alerting  â”‚ â”‚
â”‚  â”‚             â”‚  â”‚             â”‚  â”‚   Traces)   â”‚  â”‚            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                â”‚                â”‚               â”‚
          â–¼                â–¼                â–¼               â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Prometheus  â”‚  â”‚AlertManager â”‚  â”‚    Loki     â”‚  â”‚   Tempo    â”‚
   â”‚  (Metrics)  â”‚  â”‚  (Routing)  â”‚  â”‚   (Logs)    â”‚  â”‚  (Traces)  â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
          â”‚                                  â”‚               â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   FastAPI App       â”‚
              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
              â”‚  â”‚ /metrics      â”‚â”€â”€â”¼â”€â”€â–¶ Prometheus
              â”‚  â”‚ structlog     â”‚â”€â”€â”¼â”€â”€â–¶ Loki (via Promtail)
              â”‚  â”‚ OpenTelemetry â”‚â”€â”€â”¼â”€â”€â–¶ Tempo
              â”‚  â”‚ Sentry SDK    â”‚â”€â”€â”¼â”€â”€â–¶ Sentry
              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## References

- `_references/DEPLOYMENT-PATTERN.md`
- `33-cicd/SKILL.md` - CI/CDì™€ Prometheus ì—°ë™

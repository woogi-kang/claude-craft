# 멀티-LLM 컨센서스 리포트: PRD (Product Requirements Document)

> 생성일시: 2026-01-16
> 리뷰 대상: testcraft/04-specification/prd.md
> 리뷰어: Claude (Anthropic), Gemini (Google)

---

## 1. 종합 평가

| 항목 | Claude | Gemini | 컨센서스 |
|------|--------|--------|----------|
| 전체 점수 | 6.5/10 | 4.0/10 | **5.5/10** |
| Critical | 2 | 2 | 2 |
| Major | 5 | 2 | 4 |
| Minor | 3 | 1 | 2 |
| Suggestion | 3 | 0 | 2 |

**가중 평균 점수**: 5.5/10 (Claude 60% + Gemini 40% 가중치)

⚠️ **경고**: PRD 문서에 심각한 일관성 문제가 발견되었습니다. 개발 착수 전 수정 필요.

---

## 2. 컨센서스 이슈 (양측 동의) - CRITICAL

### 🚨 CRITICAL: 비즈니스 메트릭 수학적 불일치
**합의율: 100%** ⭐ 핵심 이슈

| 관점 | Claude | Gemini |
|------|--------|--------|
| 이슈 | MRR $5,000 목표가 가격 구조와 불일치 | 비즈니스 지표 간 모순 |
| 분석 | 100 MAU × 10% 전환 = 10명 유료, $5,000 MRR 달성하려면 ARPU $500 필요 | $10-25 가격대 가정과 MRR 목표가 맞지 않음 |
| 제안 | MAU 목표 상향 또는 MRR 목표 하향 조정 | 현실적인 지표 재계산 필요 |

**권장 조치**:
```
현재: 100 MAU × 10% × $20 = $200 MRR
목표 달성 필요: 2,500 MAU × 10% × $20 = $5,000 MRR
```
MAU 목표를 2,500+로 상향하거나 MRR 목표를 $200-500으로 하향 조정

---

### 🚨 CRITICAL: MVP 4-6주 일정 비현실적
**합의율: 100%** ⭐ 핵심 이슈

| 관점 | Claude | Gemini |
|------|--------|--------|
| 이슈 | 1인 개발로 4주 MVP 불가능 | 4-6주에 핵심 기능 모두 구현 비현실적 |
| 분석 | F-001~F-009 기능 + 인프라 + 테스트는 최소 8-12주 소요 | PDF 파싱 + AI 통합 + 인증 + UI를 4주에 불가 |
| 제안 | 일정 2배 또는 범위 절반으로 축소 | 핵심 기능 3-4개로 MVP 재정의 |

**권장 조치**:
- Option A: 일정을 8-12주로 연장
- Option B: MVP를 F-003(업로드), F-005(AI 생성), F-009(Export)만으로 축소
- Option C: 팀원 추가 (2인 이상)

---

## 3. 컨센서스 이슈 (양측 동의) - MAJOR

### ⚠️ MAJOR: 시간 지표 모순 (5분 vs 60초)
**합의율: 100%**

| 관점 | Claude | Gemini |
|------|--------|--------|
| 이슈 | "TC 5분 생성" 비전 vs "60초 이내" NFR 불일치 | 5분 Hero Experience vs 60초 성능 요구사항 충돌 |
| 제안 | 비전과 NFR 일치시키기 (예: "TC 생성 3분 이내") | 단계별 시간 정의 (업로드 30초, 생성 3분, 후처리 90초) |

**권장 조치**: "PRD → TC 5분" 비전 유지, NFR을 "AI 생성 단계 180초 이내"로 수정

---

### ⚠️ MAJOR: MAU 성장 목표 비현실적
**합의율: 100%**

| 관점 | Claude | Gemini |
|------|--------|--------|
| 이슈 | 100 → 1,000 MAU 성장 전략 부재 | 10배 성장을 위한 구체적 채널/전략 없음 |
| 제안 | 마케팅 채널, CAC별 예상 획득 수 명시 | 단계별 성장 로드맵 및 핵심 전환 포인트 정의 |

---

## 4. Claude 단독 발견 사항

### ⚠️ MAJOR: 인수 조건(Acceptance Criteria) 부재
- **위치**: 핵심 기능 섹션
- **이슈**: 모든 기능에 인수 조건이 없음
- **제안**: 각 F-00X에 "Given-When-Then" 형식 인수 조건 추가

### ⚠️ MAJOR: 동시 사용자 1,000명 과잉
- **위치**: 비기능 요구사항
- **이슈**: 100 MAU 목표에 1,000 동시 사용자 스펙은 과도한 엔지니어링
- **제안**: 초기에는 50 동시 사용자로 시작, 스케일 전략 별도 정의

### ⚠️ MAJOR: 사용자 여정(User Journey) 부재
- **위치**: 타겟 사용자 섹션
- **이슈**: 페르소나만 있고 실제 사용 흐름 없음
- **제안**: Primary 사용자의 일주일 시나리오 추가

### 📝 MINOR: 용어 일관성 부족
- **위치**: 전체 문서
- **이슈**: "TC", "테스트케이스", "Test Case" 혼용
- **제안**: 용어 사전 추가, 일관된 용어 사용

---

## 5. Gemini 단독 발견 사항

### ⚠️ MAJOR: 핵심 기술 리스크 미검증
- **위치**: 리스크 섹션
- **이슈**: PDF 파싱 + AI 품질이 제품의 핵심인데 검증 계획 없음
- **제안**: MVP 전 POC(개념 증명) 단계 추가하여 핵심 기술 검증

### 📝 MINOR: 경쟁사 분석 부재
- **위치**: 리스크 섹션
- **이슈**: "경쟁사 AI 출시" 리스크 언급하나 현재 경쟁 환경 분석 없음
- **제안**: 간단한 경쟁사 비교표 추가

---

## 6. 강점 (양측 인정)

| Claude | Gemini |
|--------|--------|
| 명확한 제품 비전 | 핵심 가치 제안의 명확성 |
| 체계적인 MoSCoW 우선순위 | 기능 분류 체계 |
| 플랫폼별 엣지케이스 상세화 | 도메인 전문성 (QA/테스팅) |
| 릴리스 로드맵 단계 구분 | 점진적 기능 확장 계획 |

---

## 7. 개선 우선순위

### P0 (즉시 - 개발 착수 전 필수)
1. 🔴 비즈니스 메트릭 재계산 (MRR, MAU 정합성)
2. 🔴 MVP 일정 현실화 (8-12주) 또는 범위 축소
3. 🔴 시간 지표 통일 (5분 vs 60초)

### P1 (Sprint 0)
4. 핵심 기술 POC 계획 수립 (PDF 파싱 + AI 품질)
5. 인수 조건 작성 (최소 Must Have 기능)
6. Primary 사용자 여정 정의

### P2 (MVP 중)
7. 동시 사용자 스펙 현실화
8. 용어 사전 및 일관성 정리
9. 경쟁사 분석 추가

---

## 8. 메타 분석

**Claude vs Gemini 관점 차이:**
- **Claude**: 문서 완성도 관점 (인수 조건, 용어 일관성, 사용자 여정)
- **Gemini**: 실행 가능성 관점 (일정 현실성, 기술 리스크, 시장 검증)

**점수 차이 분석** (6.5 vs 4.0):
- Gemini가 더 엄격한 실행 가능성 기준 적용
- Claude는 문서 구조적 완성도에 더 높은 점수 부여
- 컨센서스 점수 5.5는 "재작업 필요" 수준

**리뷰 신뢰도**: 매우 높음 (Critical 이슈에 대한 완벽한 합의)

---

## 9. 권장 다음 단계

```
1. [ ] 비즈니스 메트릭 워크숍 (2시간)
   - MRR/MAU/전환율/가격 정합성 재계산

2. [ ] MVP 범위 재정의 (1시간)
   - 핵심 3-4개 기능으로 축소 검토

3. [ ] 기술 POC 계획 (30분)
   - PDF 파싱 + GPT-4 TC 생성 품질 검증 방법

4. [ ] PRD v2 작성 (4시간)
   - 위 이슈 반영한 개정판
```

---

*이 리포트는 멀티-LLM 앙상블 리뷰 시스템에 의해 자동 생성되었습니다.*
